function _precompile_()
    ccall(:jl_generating_output, Cint, ()) == 1 || return nothing
    precompile(Tuple{typeof(Tokenize.Lexers.is_identifier_char), Char})
    precompile(Tuple{typeof(Tokenize.Lexers.dotop2), Char, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.is_operator_start_char), UInt32})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_comment), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Bool})
    precompile(Tuple{typeof(Tokenize.Lexers.is_cat_id_start), Char, Int32})
    precompile(Tuple{typeof(Tokenize.Lexers.readutf), Base.GenericIOBuffer{Array{UInt8, 1}}, Int64})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_dot), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_prime), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_identifier), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.readchar), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.emit), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tokenize.Tokens.Kind, Tokenize.Tokens.TokenError})
    precompile(Tuple{typeof(Tokenize.Lexers.string_terminated), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tokenize.Tokens.Kind})
    precompile(Tuple{typeof(Tokenize.Lexers.accept_number), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, typeof(Tokenize.Lexers.ishex)})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_digit), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tokenize.Tokens.Kind})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_whitespace), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char, Char, Char, Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.next_token), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Bool})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_greater), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_less), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_forwardslash), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_amper), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_minus), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char, Char, Char, Char, Char, Char, Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Char, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char, Char, Char, Char, Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_cmd), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Bool})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_bar), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char, Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char, Char, Char}, Tokenize.Tokens.Kind, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_equal), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_star), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_exclaim), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_plus), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_colon), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}})
    precompile(Tuple{typeof(Tokenize.Lexers.readrest), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Char})
    precompile(Tuple{typeof(Tokenize.Lexers.read_string), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tokenize.Tokens.Kind})
    precompile(Tuple{typeof(Tokenize.Lexers.lex_quote), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Bool})
    precompile(Tuple{typeof(Tokenize.Lexers.is_identifier_start_char), Char})
    precompile(Tuple{typeof(Tokenize.Lexers.tryread), Tokenize.Lexers.Lexer{Base.GenericIOBuffer{Array{UInt8, 1}}, Tokenize.Tokens.RawToken}, Tuple{Char, Char, Char, Char, Char, Char, Char}, Tokenize.Tokens.Kind, Char})
end
